{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy.random import shuffle\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray\n",
    "\n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "\timages_list = list()\n",
    "\tfor image in images:\n",
    "\t\t# resize with nearest neighbor interpolation\n",
    "\t\tnew_image = resize(image, new_shape, 0)\n",
    "\t\t# store\n",
    "\t\timages_list.append(new_image)\n",
    "\treturn asarray(images_list)\n",
    "\n",
    "# assumes images have any shape and pixels in [0,255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "\t# load inception v3 model\n",
    "\tmodel = InceptionV3()\n",
    "\t# enumerate splits of images/predictions\n",
    "\tscores = list()\n",
    "\tn_part = floor(images.shape[0] / n_split)\n",
    "\tfor i in range(n_split):\n",
    "\t\t# retrieve images\n",
    "\t\tix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "\t\tsubset = images[ix_start:ix_end]\n",
    "\t\t# convert from uint8 to float32\n",
    "\t\tsubset = subset.astype('float32')\n",
    "\t\t# scale images to the required size\n",
    "\t\tsubset = scale_images(subset, (299,299,3))\n",
    "\t\t# pre-process images, scale to [-1,1]\n",
    "\t\tsubset = preprocess_input(subset)\n",
    "\t\t# predict p(y|x)\n",
    "\t\tp_yx = model.predict(subset)\n",
    "\t\t# calculate p(y)\n",
    "\t\tp_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "\t\t# calculate KL divergence using log probabilities\n",
    "\t\tkl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "\t\t# sum over classes\n",
    "\t\tsum_kl_d = kl_d.sum(axis=1)\n",
    "\t\t# average over images\n",
    "\t\tavg_kl_d = mean(sum_kl_d)\n",
    "\t\t# undo the log\n",
    "\t\tis_score = exp(avg_kl_d)\n",
    "\t\t# store\n",
    "\t\tscores.append(is_score)\n",
    "\t# average across images\n",
    "\tis_avg, is_std = mean(scores), std(scores)\n",
    "\treturn is_avg, is_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Construct the module\n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.zeros(1)+.2)\n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B * C * W * H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B * N * N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        \n",
    "        proj_query  = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0,2,1) # B * N * C\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        energy =  torch.bmm(proj_query, proj_key) # batch matrix-matrix product\n",
    "        \n",
    "        attention = self.softmax(energy) # B * N * N\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        out = torch.bmm(proj_value, attention.permute(0,2,1)) # batch matrix-matrix product\n",
    "        out = out.view(m_batchsize,C,width,height) # B * C * W * H\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator\n",
    "    input: \n",
    "        z: latent matrix with shape of (batch_size, 100)\n",
    "    output: \n",
    "        out: generated image with shape (batch_size, 1, 28, 28)\n",
    "        p1: attention matrix generated by attn layer\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=64, attn=True, image_size=28, z_dim=100, conv_dim=64):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        \n",
    "        # Layer 1 turn 100 dims -> 512 dims, size 1 -> 3\n",
    "        layer1 = []\n",
    "        layer1.append(SpectralNorm(nn.ConvTranspose2d(in_channels = z_dim, out_channels = conv_dim*8, kernel_size = 3)))\n",
    "        layer1.append(nn.BatchNorm2d(conv_dim*8))\n",
    "        layer1.append(nn.ReLU())\n",
    "        self.l1 = nn.Sequential(*layer1)\n",
    "        \n",
    "        # Layer 2 turn 512 dims -> 256 dims, size 3 -> 7\n",
    "        layer2 = []\n",
    "        layer2.append(SpectralNorm(nn.ConvTranspose2d(in_channels = conv_dim*8, out_channels = conv_dim*4, \n",
    "                                                      kernel_size = 3, stride = 2, padding = 0)))\n",
    "        layer2.append(nn.BatchNorm2d(conv_dim*4))\n",
    "        layer2.append(nn.ReLU())\n",
    "        self.l2 = nn.Sequential(*layer2)\n",
    "        \n",
    "        # Layer 3 turn 256 dims -> 128 dims, size 7 -> 14\n",
    "        layer3 = []\n",
    "        layer3.append(SpectralNorm(nn.ConvTranspose2d(in_channels = conv_dim*4, out_channels = conv_dim*2, \n",
    "                                                      kernel_size = 4, stride = 2, padding = 1)))\n",
    "        layer3.append(nn.BatchNorm2d(conv_dim*2))\n",
    "        layer3.append(nn.ReLU())\n",
    "        self.l3 = nn.Sequential(*layer3)\n",
    "\n",
    "        # Layer 4 (Attn) turn 128 dims -> 128 dims\n",
    "        self.attn = Self_Attn(conv_dim*2)\n",
    "        \n",
    "        # Layer 5 turn 128 dims -> 1 dims, size 14 -> 28\n",
    "        last = []\n",
    "        last.append(nn.ConvTranspose2d(conv_dim*2, 1, 4, 2, 1))\n",
    "        last.append(nn.Tanh())\n",
    "        self.last = nn.Sequential(*last)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z is the input random matrix for generator\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        out=self.l1(z)\n",
    "        out=self.l2(out)\n",
    "        out=self.l3(out)\n",
    "        if self.attn == True:\n",
    "            out = self.attn(out)\n",
    "        out=self.last(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator\n",
    "    input:\n",
    "        x: one batch of data with shape of (batch_size, 1, 28, 28)\n",
    "    output: \n",
    "        out.squeeze: a batch of scalars indicating the predict results\n",
    "        p1: attention matrix generated by attn layer\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=64, attn=True, image_size=28, conv_dim=64):\n",
    "        super().__init__()\n",
    "        self.attn = attn\n",
    "        \n",
    "        layer1 = []\n",
    "        layer1.append(SpectralNorm(nn.Conv2d(1, conv_dim, 4, 2, 1)))\n",
    "        layer1.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = conv_dim\n",
    "        self.l1 = nn.Sequential(*layer1)\n",
    "        \n",
    "        layer2 = []\n",
    "        layer2.append(SpectralNorm(nn.Conv2d(curr_dim, curr_dim * 2, 4, 2, 1)))\n",
    "        layer2.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = curr_dim * 2\n",
    "        self.l2 = nn.Sequential(*layer2)\n",
    "        \n",
    "        layer3 = []\n",
    "        layer3.append(SpectralNorm(nn.Conv2d(curr_dim, curr_dim * 2, 4, 2, 1)))\n",
    "        layer3.append(nn.LeakyReLU(0.1))\n",
    "        curr_dim = curr_dim * 2\n",
    "        self.l3 = nn.Sequential(*layer3)\n",
    "        \n",
    "        self.attn = Self_Attn(curr_dim)\n",
    "        \n",
    "        last = []\n",
    "        last.append(nn.Conv2d(curr_dim, 1, 4, 2, 1))\n",
    "        self.last = nn.Sequential(*last)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        out = self.l3(out)\n",
    "        if self.attn == True:\n",
    "            out = self.attn(out)\n",
    "        out=self.last(out)\n",
    "\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Utility functions\n",
    "def cuda(data):\n",
    "    if torch.cuda.is_available():\n",
    "        return data.cuda()\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n",
    "\n",
    "# Define data transformer\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Read data and transform\n",
    "dataset = MNIST(root='./data', download=True, train=True, transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Fix a random latent input for samples\n",
    "fixed_z = cuda(torch.randn(64, 100))\n",
    "fixed_z1 = cuda(torch.randn(10000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscore = []\n",
    "def train(steps = 100000, batch_size = 64, z_dim = 100, attn = True):\n",
    "    # Initialize model\n",
    "    G = cuda(Generator(batch_size, attn))\n",
    "    D = cuda(Discriminator(batch_size, attn))\n",
    "    \n",
    "    # Make directory for samples and models\n",
    "    cwd = os.getcwd()\n",
    "    post='_attn' if attn else ''\n",
    "    if not os.path.exists(cwd+'/samples_mnist'+post):\n",
    "        os.makedirs(cwd+'/samples_mnist'+post)\n",
    "\n",
    "    # Initialize optimizer with filter, lr and coefficients\n",
    "    g_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, G.parameters()), 0.0001, [0.0,0.9])\n",
    "    d_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, D.parameters()), 0.0004, [0.0,0.9])\n",
    "    \n",
    "    # Load data\n",
    "    Iter = iter(dataloader)\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # ================== Train D ================== #\n",
    "        D.train(); G.train()\n",
    "        try:\n",
    "            real_images,_ = next(Iter)\n",
    "        except:\n",
    "            Iter = iter(dataloader)\n",
    "            real_images,_ = next(Iter)\n",
    "        \n",
    "        # Compute loss with real images\n",
    "        d_out_real = D(cuda(real_images))\n",
    "        d_loss_real = torch.nn.ReLU()(1.0 - d_out_real).mean()\n",
    "        \n",
    "        # Compute loss with fake images\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        d_out_fake = D(fake_images)\n",
    "        d_loss_fake = torch.nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "        \n",
    "        # Backward + Optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ================== Train G ================== #\n",
    "        # Create random noise\n",
    "        z = cuda(torch.randn(batch_size, z_dim))\n",
    "        fake_images = G(z)\n",
    "        g_out_fake = D(fake_images)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "        d_optimizer.zero_grad(); g_optimizer.zero_grad()\n",
    "        g_loss_fake.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Print out log info\n",
    "        if (step + 1) % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            expect = elapsed/(step + 1)*(steps-step-1)\n",
    "            elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "            expect = str(datetime.timedelta(seconds=expect))\n",
    "            clear_output(wait=True)\n",
    "            print(\"Elapsed [{}], Expect [{}], step [{}/{}], D_real_loss: {:.4f}, \"\n",
    "                  \" ave_generator_gamma: {:.4f}\".\n",
    "                  format(elapsed,expect,step + 1,steps,d_loss_real.item(),G.attn.gamma.mean().item()))\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Sample images\n",
    "        if (step + 1) % (100) == 0:\n",
    "            fake_images= G(fixed_z)\n",
    "            save_image(denorm(fake_images), os.path.join('./samples_mnist'+post, '{}_fake.png'.format(step + 1)))\n",
    "\n",
    "          \n",
    "        # Save models\n",
    "        #if (step+1) % (100) == 0:\n",
    "            #torch.save(G.state_dict(),os.path.join('./models', '{}_G.pth'.format(step + 1)))\n",
    "            #torch.save(D.state_dict(),os.path.join('./models', '{}_D.pth'.format(step + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(steps = 60000, attn = False)\n",
    "#print('Done training part 1')\n",
    "train(steps = 60000, attn = True)\n",
    "print('Done training part 2')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mytension')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6c34e26e911754d9e5d8ad53c6c4b28f3222f166c3c6db35ab8b1fb05f9dc4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
