{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Image using Attention GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parts of this code is adapted from https://github.com/AloneTogetherY/text-to-image-synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "KQLnyKmcvOgL",
    "outputId": "d45d7f72-cb8c-424f-a899-cfe8193196d4"
   },
   "outputs": [],
   "source": [
    "# importing files\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gensim\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from random import randint,choice\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import RandomNormal\n",
    "from numpy.random import random\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import time\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "\n",
    "### Image Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the image and storing as numpy file\n",
    "embedding_file = os.path.join('./embeddings/',\n",
    "        f'birds_image_embedding') \n",
    "start = time.time()\n",
    "print(\"Loading training images...\")\n",
    "\n",
    "training_data = []\n",
    "# flowers_path = sorted(os.listdir(DATA_PATH))\n",
    "\n",
    "\n",
    "birds_path = sorted(os.listdir('./images/'))\n",
    "\n",
    "for filename in range(len(birds_path)):\n",
    "    path = os.path.join('./images/',birds_path[filename])\n",
    "    if path.endswith('.jpg'):\n",
    "      try:\n",
    "        image = Image.open(path).resize((64,64),Image.ANTIALIAS) # reducing the image size into 64px\n",
    "        channel = np.asarray(image).shape[2]\n",
    "\n",
    "        training_data.append(np.asarray(image))\n",
    "\n",
    "          \n",
    "      except:\n",
    "        print(birds_path[filename])\n",
    "training_data = np.reshape(training_data,(-1,64,64,3))     #reshaping numpy array into (64,64,3)\n",
    "training_data = training_data.astype(np.float32)\n",
    "     \n",
    "training_data = training_data / 127.5 - 1.            #Normalizing the input\n",
    "\n",
    "print(\"Image embedding finished and saving...\")\n",
    "training_data = training_data[:11776]\n",
    "np.save(embedding_file + \".npy\",training_data)\n",
    "\n",
    "print (f'Time taken to complete embedding: {time.time()-start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of code is for text embedding\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "vw = np.zeros((11776,52,300))\n",
    "def clean_and_tokenize_comments_for_image(comment):\n",
    "    stop_words = ['a', 'and', 'of', 'to']\n",
    "    punctuation = r\"\"\"!\"#$%&'()*+,./:;<=>?@[\\]^_`…’{|}~\"\"\"\n",
    "    comments_without_punctuation = [s.translate(str.maketrans(' ', ' ', punctuation)) for s in comment]\n",
    "    sentences = []\n",
    "\n",
    "    for q_w_c in comments_without_punctuation:\n",
    "        q_w_c = re.sub(r\"-(?:(?<!\\b[0-9]{4}-)|(?![0-9]{2}(?:[0-9]{2})?\\b))\", ' ', q_w_c)  # replace with space\n",
    "\n",
    "        temp_tokens = word_tokenize(str(q_w_c).lower())\n",
    "        tokens = [t for t in temp_tokens if t not in stop_words]\n",
    "        sentences.append(tokens)\n",
    "    return sentences\n",
    "    \n",
    "def getword2vec(word2vec_model, cleaned_comments):\n",
    "    vectorized_list = []\n",
    "    sentence_vlist = []\n",
    "    cleaned_caption = clean_and_tokenize_comments_for_image(cleaned_comments)\n",
    "    # print(cleaned_caption)\n",
    "    for i,words in enumerate(cleaned_caption):\n",
    "        result_array = np.empty((0, 300))\n",
    "        if i == 11776:\n",
    "            break\n",
    "        for word in words:\n",
    "            \n",
    "            try:\n",
    "                    w = [word2vec_model[word]]\n",
    "                    result_array = np.append(result_array, w, axis=0)\n",
    "            except KeyError:\n",
    "                if word in 'superciliary' or word in 'superciliaries':\n",
    "                    result_array = np.append(result_array, [word2vec_model['eyebrow']], axis=0)\n",
    "                    result_array = np.append(result_array, [word2vec_model['region']], axis=0)\n",
    "                elif word in 'rectrices' or word in 'rectices':\n",
    "                    result_array = np.append(result_array, [word2vec_model['large']], axis=0)\n",
    "                    result_array = np.append(result_array, [word2vec_model['tail']], axis=0)\n",
    "                    result_array = np.append(result_array, [word2vec_model['feathers']], axis=0)\n",
    "                else:\n",
    "                    result_array = np.append(result_array, [word2vec_model[random.choice(word2vec_model.index_to_key)]], axis=0)\n",
    "\n",
    "        vectorized_list.append(result_array.astype('float32'))\n",
    "        sentence_vlist.append(result_array.mean(axis=0).astype('float32'))\n",
    "\n",
    "    return np.asarray(vectorized_list,dtype='object'),np.asarray(sentence_vlist).astype('float32')\n",
    "df = pd.read_csv('final.csv')\n",
    "all_captions = df['captions'].values\n",
    "vector_word,vector_sentence = getword2vec(model,all_captions)\n",
    "\n",
    "\n",
    "for i in range(len(vector_sentence)):\n",
    "    vw[i,:vector_word[i].shape[0]] = vector_word[i]       #padding vector\n",
    "\n",
    "np.save('./embeddings/bird_sentence_vector.npy',vector_sentence)  \n",
    "np.save('./embeddings/bird_word_features.npy',vw)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding = np.load('./embeddings/birds_image_embedding.npy')\n",
    "vw = np.load('./embeddings/bird_word_features.npy')\n",
    "vector_sentence = np.load('./embeddings/bird_sentence_vector.npy')\n",
    "\n",
    "captions = pd.read_csv('./captions.csv')\n",
    "captions = captions['captions'][:11776]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator model\n",
    "def define_discriminator():\n",
    "    word_vector_dim = 300\n",
    "    dropout_prob = 0.4\n",
    "\n",
    "    in_label = layers.Input(shape=(300,))\n",
    "\n",
    "    n_nodes = 3 * 64 * 64\n",
    "    li = layers.Dense(n_nodes)(in_label)\n",
    "    li = layers.Reshape((64, 64, 3))(li)\n",
    "\n",
    "    dis_input = layers.Input(shape=(64, 64, 3))\n",
    "\n",
    "    merge = layers.Concatenate()([dis_input, li])\n",
    "\n",
    "    discriminator = layers.Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(merge)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "    discriminator = layers.GaussianNoise(0.2)(discriminator)\n",
    "    \n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU()(discriminator)\n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "    \n",
    "    discriminator = layers.Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(discriminator)\n",
    "    discriminator = layers.BatchNormalization(momentum=0.5)(discriminator)\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "\n",
    "    discriminator = layers.Flatten()(discriminator)\n",
    "\n",
    "    discriminator = layers.Dense(1024)(discriminator)\n",
    "\n",
    "    discriminator = layers.LeakyReLU(0.2)(discriminator)\n",
    "\n",
    "    discriminator = layers.Dense(1)(discriminator)\n",
    "\n",
    "    discriminator_model = Model(inputs=[dis_input, in_label], outputs=discriminator)\n",
    "\n",
    "    discriminator_model.summary()\n",
    "\n",
    "    return discriminator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x3g-rNcqr4lX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def resnet_block(model, kernel_size, filters, strides):\n",
    "    gen = model\n",
    "    model = layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=\"same\")(model)\n",
    "    model = layers.BatchNormalization(momentum=0.5)(model)\n",
    "    model = tf.keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1, 2])(model)\n",
    "    model = layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=\"same\")(model)\n",
    "    model = layers.BatchNormalization(momentum=0.5)(model)\n",
    "    model = layers.Add()([gen, model])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Generator model\n",
    "def define_generator():\n",
    "    kernel_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    batch_init = tf.random_normal_initializer(1., 0.02)\n",
    "   \n",
    "    random_input = layers.Input(shape=(100,))\n",
    "    text_input1 = layers.Input(shape=(300,))\n",
    "    text_layer1 = layers.Dense(8192)(text_input1)\n",
    "    text_layer1 = layers.Reshape((8, 8, 128))(text_layer1)\n",
    "\n",
    "    n_nodes = 128 * 8 * 8\n",
    "    gen_input_dense = layers.Dense(n_nodes)(random_input)\n",
    "    generator = layers.Reshape((8, 8, 128))(gen_input_dense)\n",
    "\n",
    "    merge = layers.Concatenate()([generator, text_layer1])\n",
    "\n",
    "    model = layers.Conv2D(filters=64, kernel_size=9, strides=1, padding=\"same\")(merge)\n",
    "    model = tf.keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1, 2])(model)\n",
    "\n",
    "    gen_model = model\n",
    "\n",
    "    for _ in range(4):\n",
    "      model = resnet_block(model, 3, 64, 1)\n",
    "\n",
    "    model = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "    model = layers.BatchNormalization(momentum=0.5)(model)\n",
    "    model = layers.Add()([gen_model, model])\n",
    "\n",
    "    model = layers.Conv2DTranspose(filters=512, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=kernel_init)(model)\n",
    "    model = layers.LeakyReLU(0.2)(model)\n",
    "\n",
    "    model = layers.Conv2DTranspose(filters=256, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=kernel_init)(model)\n",
    "    model = layers.LeakyReLU(0.2)(model)\n",
    "\n",
    "    model = layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", kernel_initializer=kernel_init)(model)\n",
    "    model = layers.LeakyReLU(0.2)(model)\n",
    "\n",
    "    model = layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_init)(model)\n",
    "    F0_model = layers.LeakyReLU(0.2)(model)\n",
    "    # model = Model(inputs=[random_input,text_input1], outputs=[model])\n",
    "    G0_model = layers.Conv2D(3, (3, 3), padding='same', activation='tanh')(F0_model)\n",
    "\n",
    "    generator_model = Model(inputs=[random_input,text_input1], outputs=[G0_model,F0_model])\n",
    "    generator_model.summary()\n",
    "\n",
    "    return generator_model\n",
    "# define_generator()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention module implemented by myself\n",
    "\n",
    "\n",
    "def attention_module():\n",
    "    \n",
    "    # masking_vector = layers.Input(shape=(52,4096))\n",
    "\n",
    "    word_feature = layers.Input(shape=(52,300))            # word vectors of feature 300 as input\n",
    "    new_word_feature = layers.Dense(64)(word_feature)    # changing word vector to (T,64)\n",
    "\n",
    "    f0_output = layers.Input(shape=(64,64,64))           # f0 output is given as input (64,64,64)\n",
    "    new_f0_output = layers.Reshape((64,64*64))(f0_output) # changing shape to (64,4096)\n",
    "    \n",
    "    s_function = tf.matmul(new_word_feature,new_f0_output) # matmul of (T,64)x(64,4096)\n",
    "    \n",
    "    nsd = tf.where(s_function!=0,s_function,tf.float64.min)\n",
    "    beta = layers.Softmax(axis=0)(nsd) \n",
    "    new_beta = tf.where(tf.math.is_nan(beta), tf.zeros_like(beta), beta)                 \n",
    "    \n",
    "    c = tf.einsum('ijk,ijl->ikl', new_beta, new_word_feature)  # finding the vector c\n",
    "    c = tf.linalg.matrix_transpose(c)\n",
    "    attnout = layers.Reshape((64,64,64))(c)                   # reshaping the output to (64,64,64)\n",
    "    \n",
    "    model = Model(inputs=([word_feature, f0_output]),outputs=([attnout]))\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function defining second generator \n",
    "\n",
    "def define_F1():\n",
    "\n",
    "    input1 = layers.Input(shape=(64,64,64))\n",
    "    input2 = layers.Input(shape=(64,64,64))\n",
    "\n",
    "    input1_2 = layers.Concatenate(axis=3)([input1,input2])\n",
    "    \n",
    "    conv2d4 = layers.Conv2DTranspose(64,kernel_size=4,padding=\"same\",kernel_initializer=initializers.RandomNormal(stddev=0.02))(input1_2)\n",
    "    batchNorm4 = layers.BatchNormalization(momentum=0.8)(conv2d4)\n",
    "    model = layers.LeakyReLU(alpha=0.2)(batchNorm4)\n",
    "\n",
    "    for _ in range(4):\n",
    "      model = resnet_block(model, 3, 64, 1)\n",
    "\n",
    "   \n",
    "    G1_model = layers.Conv2D(3, (3, 3), padding='same', activation='tanh')(model)\n",
    "  \n",
    "    generator_model = Model(inputs=[input1,input2], outputs=[G1_model])\n",
    "    generator_model.summary()\n",
    "    return generator_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "\n",
    "def generate_random_vectors(n_samples):  \n",
    "  vectorized_random_captions = []\n",
    "\n",
    "  for n in range(n_samples):\n",
    "    rnd = randint(8, 25)\n",
    "    result_array = np.empty((0, 300))\n",
    "    for i in range(rnd):\n",
    "      result_array = np.append(result_array, [model[choice(model.index_to_key)]], axis=0)\n",
    "    vectorized_random_captions.append(np.mean(result_array, axis=0).astype('float32'))\n",
    "\n",
    "  return np.array(vectorized_random_captions)\n",
    "\n",
    "def get_random_word_vectors_from_dataset(n_samples):\n",
    "  ix = np.random.randint(0, len(vector_sentence), n_samples)\n",
    "  return np.asarray(vector_sentence)[ix],tf.convert_to_tensor(np.asarray(vw)[ix])\n",
    "\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input  = tf.random.normal([n_samples, latent_dim])\n",
    "    text_captions,word_f = get_random_word_vectors_from_dataset(n_samples)\n",
    "    return [x_input, text_captions,word_f]  \n",
    "  \n",
    "\n",
    "def generate_and_save_images(model1,att, model2, epoch, test_input,word_f):\n",
    "  \n",
    "  predictions = model1(test_input, training=False)\n",
    "  attn = att([word_f,predictions[1]],training = False)\n",
    "  final_image = model2([predictions[1],attn],training = False)\n",
    "  print(predictions[1].shape)\n",
    "  pyplot.figure(figsize=[7, 7])\n",
    "\n",
    "  for i in range(predictions[1].shape[0]):\n",
    "      pyplot.subplot(5, 5, i+1)\n",
    "      pyplot.imshow(array_to_img(predictions[0].numpy()[i]))\n",
    "      pyplot.axis('off')\n",
    "\n",
    "  pyplot.savefig('Samples/G0/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  pyplot.show()\n",
    "  \n",
    "  print(final_image.shape)\n",
    "  pyplot.figure(figsize=[7, 7])\n",
    "\n",
    "  for i in range(final_image.shape[0]):\n",
    "      pyplot.subplot(5, 5, i+1)\n",
    "      pyplot.imshow(array_to_img(final_image.numpy()[i]))\n",
    "      pyplot.axis('off')\n",
    "\n",
    "  pyplot.savefig('Samples/G1/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_image_real_text, fake_image_real_text, real_image_fake_text):\n",
    "    real_loss = cross_entropy(tf.random.uniform(real_image_real_text.shape,0.8,1.0), real_image_real_text)\n",
    "    fake_loss = (cross_entropy(tf.random.uniform(fake_image_real_text.shape,0.0,0.2), fake_image_real_text) + \n",
    "                 cross_entropy(tf.random.uniform(real_image_fake_text.shape,0.0,0.2), real_image_fake_text))/2\n",
    "\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "  random_captions = generate_random_vectors(BATCH_SIZE)\n",
    "  \n",
    "  with tf.GradientTape() as gen_tape1, tf.GradientTape() as disc_tape1:\n",
    "    noise = tf.random.normal([64,100])\n",
    "   \n",
    "    generated_images1 = generator([noise,batch[1]], training=True)\n",
    "\n",
    "    fake_output_real_text1 = discriminator1([generated_images1[0], batch[1]], training=True)\n",
    "    real_output_real_text = discriminator1([batch[0], batch[1]], training=True)\n",
    "    real_output_fake_text = discriminator1([batch[0], random_captions], training=True)\n",
    "\n",
    "\n",
    "    gen_loss1 = generator_loss(fake_output_real_text1)    # #     #### Calculating losses ####\n",
    "    disc_loss_1 = discriminator_loss(real_output_real_text, fake_output_real_text1, real_output_fake_text)\n",
    "\n",
    "\n",
    "  gradients_of_discriminator = disc_tape1.gradient(disc_loss_1, discriminator1.trainable_variables)  \n",
    "  gradients_of_generator = gen_tape1.gradient(gen_loss1, generator.trainable_variables)    \n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator1.trainable_variables))\n",
    "  \n",
    "  #################################################################################################################\n",
    "  \n",
    "  \n",
    "  with tf.GradientTape() as gen_tape2, tf.GradientTape() as disc_tape2:\n",
    "    \n",
    "\n",
    "    att_out = att([batch[2],generated_images1[1]],training = True)          #### Attention Block\n",
    "    generated_images2 = F1_block([att_out,generated_images1[1]],training = True)          #### F1 Block\n",
    "\n",
    "\n",
    "    fake_output_real_text2 = discriminator2([generated_images2, batch[1]], training=True)\n",
    "    real_output_real_text2 = discriminator2([batch[0], batch[1]], training=True)\n",
    "    real_output_fake_text2 = discriminator2([batch[0], random_captions], training=True)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    gen_loss2 = generator_loss(fake_output_real_text2)  # #     #### Calculating losses ####\n",
    "    disc_loss_2 = discriminator_loss(real_output_real_text2, fake_output_real_text2, real_output_fake_text2)\n",
    "  \n",
    "\n",
    "  gradients_of_discriminator2 = disc_tape2.gradient(disc_loss_2, discriminator2.trainable_variables)  \n",
    "  gradients_of_generator2 = gen_tape2.gradient(gen_loss2, F1_block.trainable_variables)    \n",
    "  generator_optimizer2.apply_gradients(zip(gradients_of_generator2, F1_block.trainable_variables))\n",
    "  discriminator_optimizer2.apply_gradients(zip(gradients_of_discriminator2, discriminator2.trainable_variables))\n",
    "  \n",
    "  return gen_loss1+gen_loss2,disc_loss_1+disc_loss_2\n",
    "\n",
    "\n",
    "def train(data, epochs = 1000):\n",
    "  checkpoint_dir = 'checkpoints'\n",
    "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "  checkpoint1 = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                  generator=generator,\n",
    "                                  discriminator=discriminator1)\n",
    "  checkpoint2 = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                  generator=F1_block,\n",
    "                                  discriminator=discriminator2)                                \n",
    "  \n",
    "  ckpt_manager1 = tf.train.CheckpointManager(checkpoint1, checkpoint_dir, max_to_keep=3)\n",
    "  ckpt_manager2 = tf.train.CheckpointManager(checkpoint2, checkpoint_dir, max_to_keep=3)\n",
    "  print(ckpt_manager1.latest_checkpoint,'1-----------------------------------------')\n",
    "  print(ckpt_manager2.latest_checkpoint,'2-----------------------------------------')\n",
    "  if ckpt_manager1.latest_checkpoint:\n",
    "    checkpoint1.restore(ckpt_manager1.latest_checkpoint)  #ckpt_manager.checkpoints[3]\n",
    "    print ('Latest checkpoint1 restored!!')\n",
    "  if ckpt_manager2.latest_checkpoint:\n",
    "    checkpoint2.restore(ckpt_manager2.latest_checkpoint)  #ckpt_manager.checkpoints[3]\n",
    "    print ('Latest checkpoint2 restored!!')\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    genloss =[]\n",
    "    discloss =[]\n",
    "    for batch in data:\n",
    "      loss = train_step(batch)\n",
    "      genloss.append(loss[0])\n",
    "      discloss.append(loss[1]) \n",
    "    tf.print('G_loss =====',sum(genloss)/len(genloss))\n",
    "    tf.print('D_loss =====',sum(discloss)/len(discloss))\n",
    "    if (epoch +1) % 1 == 0:\n",
    "      [z_input, labels_input,word_f] = generate_latent_points(100, 25)\n",
    "      generate_and_save_images(generator,att,F1_block,epoch+1,[z_input, labels_input],word_f) \n",
    "    \n",
    "    if (epoch + 1) % 30 == 0:\n",
    "      ckpt_save_path = ckpt_manager1.save()\n",
    "      ckpt_save_path = ckpt_manager2.save()\n",
    "      print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n",
    "\n",
    "    if (epoch +1) % 50 == 0:\n",
    "    \n",
    "      clear_output(wait=True)\n",
    "      generator.save('models/g0/stage_new_gan_animal_model_%03d.h5' % (epoch + 1)) \n",
    "      F1_block.save('models/g1/stage_new_gan_animal_model_%03d.h5' % (epoch + 1))\n",
    "       \n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "\n",
    "binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.000035, beta_1 = 0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.000035, beta_1 = 0.5)\n",
    "generator_optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.000035, beta_1 = 0.5)\n",
    "discriminator_optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.000035, beta_1 = 0.5)\n",
    "\n",
    "att = attention_module()\n",
    "F1_block = define_F1()\n",
    "generator = define_generator()\n",
    "discriminator1 = define_discriminator()\n",
    "discriminator2 = define_discriminator()\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 11776\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((image_embedding,vector_sentence,vw)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Text2Image-GAN-MS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mytension')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6c34e26e911754d9e5d8ad53c6c4b28f3222f166c3c6db35ab8b1fb05f9dc4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
